{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digitale Techniken: Introduction to Python | example for data analysis\n",
    "2023-10, johanna.kerch@uni-goettingen.de, goeran.liebs@uni-goettingen.de\n",
    "\n",
    "\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" style=\"height:50px\" align=\"left\"/> <br><br>\n",
    "\n",
    "https://creativecommons.org/licenses/by-nc-sa/4.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some true data from ice core EPICA Dome C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data download from _NOAA World Data Service for Paleoclimatology Paleo Data Search Web Service_<br>\n",
    "https://www.ncdc.noaa.gov/paleo-search/ (2021-11)\n",
    "\n",
    "EPICA Dome C data: CO2, dust, temperature estimate\n",
    "\n",
    "Publications:<br>\n",
    "- LÃ¼thi, D., M. Le Floch, B. Bereiter, T. Blunier, J.-M. Barnola, U. Siegenthaler, D. Raynaud, J. Jouzel, H. Fischer, K. Kawamura, and T.F. Stocker. 2008. __High-resolution carbon dioxide concentration record 650,000-800,000 years before present.__ Nature, Vol. 453, pp. 379-382, 15 May 2008. \n",
    "- Lambert, F., B. Delmonte, J.R. Petit, M. Bigler, P.R. Kaufmann, M.A. Hutterli, T.F. Stocker, U. Ruth, J.P. Steffensen and V. Maggi. 2008. __Dust-climate couplings over the past 800,000 years from the EPICA Dome C ice core.__ Nature, Vol. 452, pp. 616-619, 3 April 2008. \n",
    "- Jouzel, J., V. Masson-Delmotte, O. Cattani, G. Dreyfus, S. Falourd, G. Hoffmann, B. Minster, J. Nouet, J.M. Barnola, J. Chappellaz, H. Fischer, J.C. Gallet, S. Johnsen, M. Leuenberger, L. Loulergue, D. Luethi, H. Oerter, F. Parrenin, G. Raisbeck, D. Raynaud, A. Schilt, J. Schwander, E. Selmo, R. Souchez, R. Spahni, B. Stauffer, J.P. Steffensen, B. Stenni, T.F. Stocker, J.L. Tison, M. Werner, and E.W. Wolff. 2007. __Orbital and Millennial Antarctic Climate Variability over the Past 800,000 Years.__ Science, Vol. 317, No. 5839, pp.793-797, 10 August 2007. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Info__: using these open data from the NOAA repository requires me to cite the publications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remainder: Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed modules are imported. ```as``` allows to use abbreviations. Use standard abbreviations (e.g. ```np```), for good style and not to long method calling (e.g. ```Your_variable=SuperlongModulename.andsuperlongmethodname()```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np              # import modules\n",
    "import matplotlib.pyplot as plt # submodules\n",
    "import pandas as pd\n",
    "from glob import glob           # import a specific method (function)\n",
    "import os\n",
    "import re\n",
    "from io import StringIO         #IO is Input/Output, here we need just the method() StringIO()...no abbreviation\n",
    "import scipy as sp              # \n",
    "print(sp.__file__)              #where are those modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your own module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Imagine, some lines code will be reused, thus they can be defined as a function. You can save it in a new file (e.g. fancy_modulname.py) to import it and to call the method like ```fancy_modulename.empty_line_split(anystring```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def empty_line_split(string):\n",
    "      \n",
    "    \"\"\" function to split a string on an arbitrary number of empty lines \"\"\"\n",
    "\n",
    "    # regular expression is introduced by 'r'\n",
    "    # here, a minimum of two subsequent linebreaks (\\n) are defined as pattern\n",
    "    regex = r\"(?:\\n){2,}\"\n",
    "    \n",
    "    # re.split is a method of the re package to directly split according to the defined pattern\n",
    "    # analoguously to str.split()\n",
    "    # strip the string before splitting\n",
    "    return re.split(regex, string.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Summary for reading the data from exercise before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember:__ you have to adjust path incl. folder names and file index according to your file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\",\"data/NOAA_2021-05-06_EPICA_data/data/pub/data/paleo/icecore/antarctica/epica_domec\",'*.txt')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob(path)\n",
    "print(type(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(files[1],'r') as f:\n",
    "    data = f.read()\n",
    "print(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blocks_re = empty_line_split(data)\n",
    "print(blocks_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = blocks_re[22]\n",
    "\n",
    "header = d.split('\\n')[0].split()\n",
    "col_data = np.genfromtxt(StringIO(d), delimiter = None, skip_header = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data\n",
    "\n",
    "In the following some typical analysis tools are applied to the data set for demonstration purposes.\n",
    "\n",
    "__Important:__<br>\n",
    "Any (more) advanced analysis might require a prior check if the data set fulfills the requirements of the analysis, e.g. the data need to be normal distributed or must contain a minimum number of independent data points and so on. The technical feasibility alone does not allow the conclusion that an analysis technique is appropriate or sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# renaming the columns for convenience: informative names\n",
    "\n",
    "years = col_data[:,0]\n",
    "carb = col_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simplest possible plot \n",
    "# objective: to get a first impression of the data\n",
    "\n",
    "plt.plot(years, carb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective:__ obtain a function for the data set to, e.g., be able to sample data inbetween the measured data points\n",
    "\n",
    "__Task:__ interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use standard variables for more flexibility\n",
    "x = years\n",
    "y = carb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue with duplicate/non-unique x values in the data when trying to use a spline interpolation\n",
    "# that had not been a problem prior to today's demonstration, my apologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search for non-unique values in x\n",
    "\n",
    "# np.unique returns array of unique values, their indices and counts the occurences of each element of array in x\n",
    "arr, ind, cts = np.unique(x, return_index=True, return_counts=True)\n",
    "\n",
    "# x-value that occurs more than once\n",
    "print(arr[cts > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find indices in the original array x for the duplicate values found \n",
    "index = np.where(x == arr[cts > 1])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rm_x_duplicates(x,y):\n",
    "    '''Remove (successive) duplicate x-values and their y-values from arrays x,y'''\n",
    "    \n",
    "    # convert into lists\n",
    "    x_l = list(x)\n",
    "    y_l = list(y)\n",
    "\n",
    "    # compare each x-value with the last\n",
    "    for i in range(1, len(x)-1):\n",
    "        if x_l[i] == x_l[i-1]:\n",
    "            del x_l[i]\n",
    "            del y_l[i]\n",
    "        \n",
    "    # convert back to arrays\n",
    "    x_new = np.array(x_l)\n",
    "    y_new = np.array(y_l)\n",
    "    \n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xn, yn = rm_x_duplicates(x,y)\n",
    "\n",
    "# assess the new x array in the vicinity of found duplicate indices\n",
    "print(xn[525:535])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternatively, take the diff between successive elements of x to find difference of zero\n",
    "# append an element to x which is larger than the last element to match the length of the original array after applying np.diff\n",
    "# and use np.where to find the indices where the condition is False\n",
    "\n",
    "index = np.where(np.diff(np.append(x,[x[-1]+1])) != 0)\n",
    "\n",
    "xn = x[index]\n",
    "yn = y[index]\n",
    "\n",
    "print(xn[525:535])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# for spline interpolation xn, yn are used to resolve the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# create a interpolating function\n",
    "inter = interp1d(x, y, kind = 'linear')\n",
    "spline = interp1d(xn, yn, kind = 'cubic')\n",
    "# cubic spline: function is differentiable at data points (no kinks) - important feature\n",
    "\n",
    "# create x-values for the function within the limits of the data points\n",
    "xint = np.linspace(min(x), max(x),2000)\n",
    "\n",
    "# produce function output\n",
    "yline = inter(xint)\n",
    "yspline = spline(xint)\n",
    "\n",
    "# only some 60 ka are displayed to better observe the difference between linear and cubic interpolation\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(xint[50:200], yline[50:200], color=\"red\", label=\"piecewise linear interpolation\")\n",
    "plt.plot(xint[50:200], yspline[50:200], color=\"grey\", label=\"spline interpolation\")\n",
    "plt.scatter(\n",
    "    x[np.where(x>20000)[0][0]:np.where(x<80000)[0][-1]], \n",
    "    y[np.where(x>20000)[0][0]:np.where(x<80000)[0][-1]], \n",
    "    label=\"data points\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective:__ obtain a trend disregarding the cyclic variations in CO2\n",
    "\n",
    "__Task:__ linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# linear function\n",
    "def line(x, slope,intercept):\n",
    "    return slope * x + intercept    # a * x + b\n",
    "\n",
    "linreg = linregress(x,y)\n",
    "slop = linreg[0]\n",
    "interc = linreg[1]\n",
    "\n",
    "xreg = np.linspace(min(x), max(x),1000)\n",
    "yreg = line(xreg, slop, interc)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(x, y , s = 3, label= 'data points')\n",
    "plt.plot(xreg, yreg, 'r', label = 'linear regression')\n",
    "plt.legend()\n",
    "\n",
    "print('trend of carbon dioxide: increasing by ' + str(round(-slop*100000,1)) + ' ppm per 100 kyr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# what does the linreg return?\n",
    "\n",
    "linreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective:__ describe the data with a function\n",
    "\n",
    "__Task:__ fit a polynom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here, in fact, a polynom does not make much sense\n",
    "# more advanced curve fitting for time series would be appropriate (if spline fitting is not sufficient)\n",
    "\n",
    "deg = 5\n",
    "p = np.polyfit(x, y, deg)\n",
    "ypoly = np.poly1d(p)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x, y, 'd',label=\"data points\")\n",
    "plt.plot(xint, ypoly(xint), color=\"orange\", label = 'polynom')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ... tracking changes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!git checkout student_1_Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!git add 05_DT_python_data_interpol.ipynb #or use --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!git commit -m 'MAKE data interpol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!git push --set-upstream origin student_1_Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
