{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Driven Development (TDD) in Jupyter Notebooks\n",
    "\n",
    "Two of many ways of software testing with Python:\n",
    "   - Unit Test (https://docs.python.org/3/library/unittest.html)\n",
    "       * run test scripts with name-convention test_{script}.py or {script}_test.py\n",
    "   - DocString Test (https://pythontesting.net/framework/doctest/doctest-introduction/)\n",
    "       * Write the command and output you would get in the Python interpreter command line interface into the Docstring for the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unit test method, example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First inspect the function to calculate the circumference of a circle in the file ```src/circles.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.circles import circle_area as ca\n",
    "print(ca(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ca(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "So fare so good..., but if, somehow it occurs that: An Instant of whatever calls the function with a negative radius amd thus, achieves a result without any geometrical meaning, and following programming steps might fail with that useless value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(ca(-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, injoy the class in ```src.test_circles.py```. And uncommend the control structures in ``src/circles.py```, to get possitiv test results, after restarting the kernel and running test_cicles like this. Or fail them by leaving control structures as commend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from src.test_circles import TestCircleArea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TestCircleArea.run_me()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## By the why, if you like to undestand more about a module, read it with an editor of your choise and find its path in the root directory with the inspect module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "inspect.getfile(unittest) #that'll gives you a path... terminal,vim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Copy the file from root directory, to read it with this jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp /opt/conda/lib/python3.10/unittest/__init__.py Readunitestinspect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And list the folder containing the whole package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls -la /opt/conda/lib/python3.10/unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DocString test method: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pass Example\n",
    "Module showing how doctests can be included with source code\n",
    "Each '>>>' line is run as if in a python shell, and counts as a test.\n",
    "The next line, if not '>>>' is the expected output of the previous line.\n",
    "If anything doesn't match exactly (including trailing spaces), the test fails.\n",
    "'''\n",
    " \n",
    "def multiply(a, b):\n",
    "    \"\"\"\n",
    "    >>> multiply(4, 3)\n",
    "    12\n",
    "    >>> multiply('a', 3)\n",
    "    'aaa'\n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import doctest then run the ```testmod``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the doctest in verbose mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    multiply(4, 3)\n",
      "Expecting:\n",
      "    12\n",
      "ok\n",
      "Trying:\n",
      "    multiply('a', 3)\n",
      "Expecting:\n",
      "    'aaa'\n",
      "ok\n",
      "12 items had no tests:\n",
      "    __main__\n",
      "    __main__._check_imported\n",
      "    __main__._jupyterlab_variableinspector_default\n",
      "    __main__._jupyterlab_variableinspector_deletevariable\n",
      "    __main__._jupyterlab_variableinspector_dict_list\n",
      "    __main__._jupyterlab_variableinspector_displaywidget\n",
      "    __main__._jupyterlab_variableinspector_getcontentof\n",
      "    __main__._jupyterlab_variableinspector_getmatrixcontent\n",
      "    __main__._jupyterlab_variableinspector_getshapeof\n",
      "    __main__._jupyterlab_variableinspector_getsizeof\n",
      "    __main__._jupyterlab_variableinspector_is_matrix\n",
      "    __main__._jupyterlab_variableinspector_is_widget\n",
      "1 items passed all tests:\n",
      "   2 tests in __main__.multiply\n",
      "2 tests in 13 items.\n",
      "2 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>\n",
    "Now an example that will fail (looking for 2+2=5 in the test).\n",
    "\n",
    "You can see that it runs the initial multiply() still but it runs them in alphabetical order so add() goes first.\n",
    "\n",
    "Again run it normally then in verbose mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Failure Example\n",
    "Module showing how doctests can be included with source code\n",
    "Each '>>>' line is like a run in a python shell, and counts as a test.\n",
    "The next line, if not '>>>' is the expected output of the previous line.\n",
    "If anything doesn't match exactly (including trailing spaces), the test fails.\n",
    "'''\n",
    "def add(a, b):\n",
    "    '''\n",
    "    This is a test:\n",
    "    >>> add(2, 2)\n",
    "    5\n",
    "    '''\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    add(2, 2)\n",
      "Expecting:\n",
      "    5\n",
      "**********************************************************************\n",
      "File \"__main__\", line 11, in __main__.add\n",
      "Failed example:\n",
      "    add(2, 2)\n",
      "Expected:\n",
      "    5\n",
      "Got:\n",
      "    4\n",
      "Trying:\n",
      "    multiply(4, 3)\n",
      "Expecting:\n",
      "    12\n",
      "ok\n",
      "Trying:\n",
      "    multiply('a', 3)\n",
      "Expecting:\n",
      "    'aaa'\n",
      "ok\n",
      "12 items had no tests:\n",
      "    __main__\n",
      "    __main__._check_imported\n",
      "    __main__._jupyterlab_variableinspector_default\n",
      "    __main__._jupyterlab_variableinspector_deletevariable\n",
      "    __main__._jupyterlab_variableinspector_dict_list\n",
      "    __main__._jupyterlab_variableinspector_displaywidget\n",
      "    __main__._jupyterlab_variableinspector_getcontentof\n",
      "    __main__._jupyterlab_variableinspector_getmatrixcontent\n",
      "    __main__._jupyterlab_variableinspector_getshapeof\n",
      "    __main__._jupyterlab_variableinspector_getsizeof\n",
      "    __main__._jupyterlab_variableinspector_is_matrix\n",
      "    __main__._jupyterlab_variableinspector_is_widget\n",
      "1 items passed all tests:\n",
      "   2 tests in __main__.multiply\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   1 in __main__.add\n",
      "3 tests in 14 items.\n",
      "2 passed and 1 failed.\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Search other test methods, nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nose as nase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(nase.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find an example... and demonstrate it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git add 023_DT_py_testmoduls.ipynb src/circles.py src/test_circles.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git  commit -m 'what about nose... instead of unittest.main in main '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
